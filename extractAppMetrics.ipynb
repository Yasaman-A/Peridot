{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/user/bin/env python\n",
    "import sys\n",
    "import string\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "import xlwt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"sparkFiles/spark-events/app-20190904192037-0001\"\n",
    "def getStages(filename):\n",
    "    stage_count = 0\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "            if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                if '\"Stage ID\":' in line:\n",
    "                    #print(line)\n",
    "                    stage_count = stage_count+1\n",
    "    \n",
    "    #print(stage_count)\n",
    "\n",
    "    return stage_count\n",
    "\n",
    "getStages(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def getTotalTasks(filename, stage):\n",
    "    total = 0\n",
    "    stage_check = '\"Stage ID\":'+str(stage)\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "                if '\"Event\":\"SparkListenerStageSubmitted\"' and stage_check in line:\n",
    "                    if '\"Number of Tasks\":' in line:\n",
    "                        partB = line.split('\"Number of Tasks\":')[1]\n",
    "                        partB = partB.split(\",\")\n",
    "                        tasks = partB[0] \n",
    "                        total = int(tasks)\n",
    "\n",
    "        return total\n",
    "print(getTotalTasks(file,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009733333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getMeanTaskTime(filename, stage):\n",
    "        \n",
    "        ttet = 0.0\n",
    "        mtet = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = getTotalTasks(file, stage)\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                        #Executor Run Time\n",
    "                                        partA = line.split('executorRunTime')[1]\n",
    "                                        partA = partA.split('\"Value\":')\n",
    "                                        tet = int(partA[1].split(',')[0])\n",
    "                                        ttet = ttet + int(tet)\n",
    "        mtet = math.ceil(ttet/count)\n",
    "        mtet = mtet/1000\n",
    "        mtet = mtet/60\n",
    "        \n",
    "        return mtet\n",
    "\n",
    "print(getMeanTaskTime(file, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0067649999999999984\n"
     ]
    }
   ],
   "source": [
    "def getMeanTaskDeserializationTime(filename,stage):\n",
    "    ttdt = 0.0\n",
    "    mtdt = 0.0\n",
    "    stage_check = '\"Stage ID\":'+str(stage)\n",
    "    count = getTotalTasks(file, stage)\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "            if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                if stage_check in line:\n",
    "                    #Executor Deserialize CPU Time\n",
    "#                     partA = line.split('executorDeserializeCpuTime')[1]\n",
    "#                     partA = partA.split('\"Value\":')\n",
    "#                     tdt = int(partA[1].split(',')[0])\n",
    "#                     converted_tdt = float(tdt)/1000000000\n",
    "                    #Executor Deserialize Time\n",
    "                    partB = line.split('\"Executor Deserialize Time\":')[1]\n",
    "                    partB = partB.split(',')\n",
    "                    tdt = int(partB[0])\n",
    "                    converted_tdt = float(tdt)/1000\n",
    "                    ttdt = ttdt + converted_tdt\n",
    "\n",
    "\n",
    "        mtdt = ttdt/count\n",
    "        mtdt = mtdt\n",
    "\n",
    "        \n",
    "    #print(ttdt)\n",
    "    return mtdt\n",
    "\n",
    "\n",
    "print(getMeanTaskDeserializationTime(file,34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# file = \"./sparkFiles/spark-events/app-20190225134146-0001\"\n",
    "# file = \"./sparkLogsData/app-20190130101035-0000\"\n",
    "def getMeanShuffleReadTime(filename, stage):\n",
    "        reference_time = 1548868837392\n",
    "        tsrt = 0.0\n",
    "        msrt = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                        partA, partB = line.split('\"Fetch Wait Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        srt = int(partB[0])\n",
    "                                        tsrt = tsrt + int(srt)\n",
    "                                        count = count + 1\n",
    "        msrt = math.ceil(tsrt/count)\n",
    "        msrt = msrt/1000\n",
    "        msrt = msrt/60\n",
    "        \n",
    "        return msrt\n",
    "\n",
    "print(getMeanShuffleReadTime(file, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005966666666666666\n"
     ]
    }
   ],
   "source": [
    "file = \"sparkFiles/spark-events/app-20200416121042-0000\"\n",
    "def getMeanGCTime(filename, stage):\n",
    "        reference_time = 1548868837392\n",
    "        tgct = 0.0\n",
    "        mgct = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        count = 0\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        partA, partB = line.split('\"JVM GC Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        gct = int(partB[0])\n",
    "                                        tgct = tgct + int(gct)\n",
    "                                        count = count + 1\n",
    "        #print(tgct)\n",
    "        mgct = math.ceil(tgct/count)\n",
    "        mgct = mgct/1000\n",
    "        mgct = mgct/60\n",
    "        return mgct\n",
    "\n",
    "print(getMeanGCTime(file,25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002965277777777779\n"
     ]
    }
   ],
   "source": [
    "def getMeanSchedulerDelay(filename, stage):\n",
    "        msd = 0\n",
    "        schedulerDelay = 0\n",
    "        count = 0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"':\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        start_time = line.split('\"Launch Time\":')[1]\n",
    "                                        start_time = start_time.split(',')[0]\n",
    "                                        finish_time = line.split('\"Finish Time\":')[1]\n",
    "                                        finish_time = finish_time.split(',')[0]\n",
    "                                        \n",
    "                                        TimestampUtc = \"\\/Date(\" + start_time + \")\\/\"\n",
    "                                        TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    \n",
    "                                        date_s = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "                                        #print (date_s)\n",
    "    \n",
    "                                        TimestampUtc = \"\\/Date(\" + finish_time + \")\\/\"\n",
    "                                        TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "                                        date_f = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "                                        #print (date_f)\n",
    "\n",
    "                                        duration = date_f - date_s\n",
    "                                        duration = str(duration)\n",
    "    \n",
    "                                        duration = duration.split(':')\n",
    "    \n",
    "                                        task_duration_in_secs = (60*60*int(duration[0])) + (60*int(duration[1])) + int(duration[2])\n",
    "\n",
    "                                        executorRunTime = line.split('\"Executor Run Time\":')\n",
    "                                        executorRunTime = executorRunTime[1].split(',')[0]\n",
    "                                        \n",
    "                                        executorDeserializeTime = line.split('\"Executor Deserialize Time\":')\n",
    "                                        executorDeserializeTime = int(executorDeserializeTime[1].split(',')[0])\n",
    "                                        \n",
    "                                        resultSerializationTime = line.split('\"Result Serialization Time\":')\n",
    "                                        resultSerializationTime = int(resultSerializationTime[1].split(',')[0])\n",
    "                                        \n",
    "                                        gettingResultTime = line.split('\"Getting Result Time\":')\n",
    "                                        gettingResultTime = int(gettingResultTime[1].split(',')[0])\n",
    "                                        \n",
    "                                        executorOverhead = float(executorDeserializeTime)/1000 + float(resultSerializationTime)/1000\n",
    "\n",
    "                                        delay = task_duration_in_secs - float(executorRunTime)/1000 - executorOverhead \\\n",
    "                                                - float(gettingResultTime)/1000000000\n",
    "\n",
    "                                        if delay <= 0:\n",
    "                                            scehdulerDelay = schedulerDelay + 0\n",
    "                                        else:\n",
    "                                            schedulerDelay = schedulerDelay + delay\n",
    "                                            \n",
    "                                        count = count+1\n",
    "                      \n",
    "        msd = schedulerDelay/count\n",
    "        msd = msd/60\n",
    "        return msd\n",
    "    \n",
    "print(getMeanSchedulerDelay(file,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def getMeanShuffleWriteTime(filename, stage):\n",
    "        tswt = 0.0\n",
    "        mswt = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        partA, partB = line.split('\"Shuffle Write Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        swt = int(partB[0])\n",
    "\n",
    "                                        tswt = tswt + int(swt)\n",
    "                                        count = count + 1\n",
    "                                        \n",
    "        print(tswt)\n",
    "        mswt = math.ceil(tswt/count)\n",
    "        mswt = mswt/1000000000\n",
    "        mswt = mswt/60\n",
    "        return mswt\n",
    "\n",
    "print(getMeanShuffleWriteTime(file, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007249999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getMedianSchedulerDelay(filename, stage):\n",
    "        msd = 0.0\n",
    "        schedulerDelay = []\n",
    "        count = 0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"':\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        \n",
    "                                        start_time = line.split('\"Launch Time\":')[1]\n",
    "                                        start_time = start_time.split(',')[0]\n",
    "                                        finish_time = line.split('\"Finish Time\":')[1]\n",
    "                                        finish_time = finish_time.split(',')[0]\n",
    "                                        \n",
    "                                        TimestampUtc = \"\\/Date(\" + start_time + \")\\/\"\n",
    "                                        TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    \n",
    "                                        date_s = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "                                        #print (date_s)\n",
    "    \n",
    "                                        TimestampUtc = \"\\/Date(\" + finish_time + \")\\/\"\n",
    "                                        TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "                                        date_f = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "                                        #print (date_f)\n",
    "\n",
    "                                        duration = date_f - date_s\n",
    "                                        duration = str(duration)\n",
    "    \n",
    "                                        duration = duration.split(':')\n",
    "    \n",
    "                                        task_duration_in_secs = (60*60*int(duration[0])) + (60*int(duration[1])) + int(duration[2])\n",
    "                                        \n",
    "                                        executorRunTime = line.split('\"Executor Run Time\":')\n",
    "                                        executorRunTime = executorRunTime[1].split(',')[0]\n",
    "                                        \n",
    "                                        executorDeserializeTime = line.split('\"Executor Deserialize Time\":')\n",
    "                                        executorDeserializeTime = executorDeserializeTime[1].split(',')[0]\n",
    "                                        \n",
    "                                        resultSerializationTime = line.split('\"Result Serialization Time\":')\n",
    "                                        resultSerializationTime = resultSerializationTime[1].split(',')[0]\n",
    "                                        \n",
    "                                        gettingResultTime = line.split('\"Getting Result Time\":')\n",
    "                                        gettingResultTime = gettingResultTime[1].split(',')[0]\n",
    "                                        \n",
    "                                        executorOverhead = float(executorDeserializeTime)/1000 + float(resultSerializationTime)/1000\n",
    "                                        \n",
    "                                        delay = task_duration_in_secs - float(executorRunTime)/1000 - executorOverhead \\\n",
    "                                                - float(gettingResultTime)/1000000000\n",
    "                                        \n",
    "                                        schedulerDelay.append(delay)\n",
    "                                        count = count + 1\n",
    "        schedulerDelay.sort()     \n",
    "        if count == 1:\n",
    "            return schedulerDelay[0]/60\n",
    "                \n",
    "        if count%2 != 0:\n",
    "            index  = (count + 1)/2\n",
    "            index = int(index)\n",
    "            msd = schedulerDelay[index-1]\n",
    "            if msd <= 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return msd/60\n",
    "        else:\n",
    "            index = count/2\n",
    "            index = int(index)\n",
    "            msd = (schedulerDelay[index-1] + schedulerDelay[index])/2\n",
    "            if msd <= 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return msd/60\n",
    "                 \n",
    "print(getMedianSchedulerDelay(file,0))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getMedianTaskTime(filename, stage):\n",
    "        reference_time = 1548868837392\n",
    "        ttet = []\n",
    "        mtet = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        #Executor Run Time\n",
    "                                        partA, partB = line.split('\"Executor Run Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        tet = float(partB[0])\n",
    "                                        tet = tet/1000\n",
    "                                        #Executor CPU Time\n",
    "#                                         partA, partB = line.split('\"Executor CPU Time\":')\n",
    "#                                         partB = partB.split(',')\n",
    "#                                         tet = tet + int(partB[0])\n",
    "\n",
    "                                        ttet.append(tet)\n",
    "                                        count = count + 1                \n",
    "        ttet.sort()\n",
    "        if count == 1:\n",
    "                return ttet[0]/60\n",
    "        \n",
    "        if count%2 != 0:\n",
    "                index  = (count + 1)/2\n",
    "                index = int(index)\n",
    "                median = ttet[index-1]/60\n",
    "                return median\n",
    "        else:\n",
    "                index = count/2\n",
    "                index = int(index)\n",
    "                median = ((ttet[index-1] + ttet[index])/2)/60\n",
    "                return median\n",
    "\n",
    "print(getMedianTaskTime(file, 27))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getMedianTaskDeserializationTime(filename, stage):\n",
    "        ttdt = []\n",
    "        mtdt = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        #Executor Desrialize Time\n",
    "                                        partA, partB = line.split('\"Executor Deserialize Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        tdt = int(partB[0])\n",
    "                                        converted_tdt = float(tdt)/1000\n",
    "                                        #Executor Deserialize CPU Time\n",
    "#                                         partA, partB = line.split('\"Executor Deserialize CPU Time\":')\n",
    "#                                         partB = partB.split(',')\n",
    "#                                         tdt = int(partB[0])\n",
    "#                                         converted_tdt = converted_tdt + float(tdt)/1000000000\n",
    "\n",
    "                                        ttdt.append(converted_tdt)\n",
    "                                        count = count + 1\n",
    "\n",
    "        ttdt.sort()\n",
    "        if count == 1:\n",
    "                return ttdt[0]/60\n",
    "        if count%2 != 0:\n",
    "                index  = (count + 1)/2\n",
    "                index = int(index)\n",
    "                median = ttdt[index-1]\n",
    "                return median/60\n",
    "        else:\n",
    "                index = count/2\n",
    "                index = int(index)\n",
    "                median = (ttdt[index-1] + ttdt[index])/2\n",
    "                return median/60\n",
    "\n",
    "print(getMedianTaskDeserializationTime(file, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def getMedianShuffleReadTime(filename, stage):\n",
    "        tsrt = []\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        partA, partB = line.split('\"Fetch Wait Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        srt = int(partB[0])\n",
    "                                        srt = srt/1000\n",
    "                                        tsrt.append(srt)\n",
    "                                        count = count + 1\n",
    "        tsrt.sort()\n",
    "        if count == 1:\n",
    "                return tsrt[0]/60 \n",
    "\n",
    "        if count%2 != 0:\n",
    "                index  = (count + 1)/2\n",
    "                index = int(index)\n",
    "                median = tsrt[index-1]\n",
    "                return median/60\n",
    "        else:\n",
    "                index = count/2\n",
    "                index = int(index)\n",
    "                median = (tsrt[index-1] + tsrt[index])/2\n",
    "                return median/60\n",
    "\n",
    "print(getMedianShuffleReadTime(file, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002402414041666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getMedianShuffleWriteTime(filename,stage):\n",
    "        tswt = []\n",
    "        mswt = 0.0\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        partA, partB = line.split('\"Shuffle Write Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        swt = int(partB[0])\n",
    "                                        swt = swt/1000000000\n",
    "                                        tswt.append(swt)\n",
    "                                        count = count + 1\n",
    "                                        \n",
    "        if count == 1:\n",
    "            return tswt[0]/60 \n",
    "        if count%2 != 0:\n",
    "            index  = (count + 1)/2\n",
    "            index = int(index)\n",
    "            median = tswt[index-1]\n",
    "            return median/60\n",
    "        else:\n",
    "            index = count/2\n",
    "            index = int(index)\n",
    "            median = (tswt[index-1] + tswt[index])/2\n",
    "            return median/60\n",
    "\n",
    "print(getMedianShuffleWriteTime(file,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def getMedianGCTime(filename, stage):\n",
    "        reference_time = 1548868837392\n",
    "        tgct = []\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        count = 0\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check in line:\n",
    "                                        partA, partB = line.split('\"JVM GC Time\":')\n",
    "                                        partB = partB.split(',')\n",
    "                                        gct = int(partB[0])\n",
    "                                        gct = float(gct)/1000\n",
    "                                        tgct.append(gct)\n",
    "                                        count = count + 1\n",
    "        tgct.sort()\n",
    "        if count == 1:\n",
    "                return tgct[0]/60 \n",
    "        elif count%2 != 0:\n",
    "                index  = (count + 1)/2\n",
    "                index = int(index)\n",
    "                median = tgct[index-1]\n",
    "                return median/60\n",
    "        else:\n",
    "                index = count/2\n",
    "                index = int(index)\n",
    "                median = (tgct[index-1] + tgct[index])/2\n",
    "                return median/60\n",
    "\n",
    "print(getMedianGCTime(file, 27))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPercentFailedTasks(filename, stage):\n",
    "        failed_tasks = 0\n",
    "        total_tasks = getTotalTasks(filename, stage)\n",
    "        stage_check = '\"Stage ID\":'+str(stage)\n",
    "        task_success_check = '{\"Reason\":\"Success\"}'\n",
    "        with open(filename) as openLog:\n",
    "                for line in openLog:\n",
    "                        if '\"Event\":\"SparkListenerTaskEnd\"' in line:\n",
    "                                if stage_check in line:\n",
    "                                    if task_success_check not in line:\n",
    "                                        failed_tasks = failed_tasks + 1\n",
    "                                        \n",
    "        \n",
    "        percent_failed_tasks = failed_tasks/total_tasks\n",
    "        return percent_failed_tasks\n",
    "\n",
    "getPercentFailedTasks(file,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def getTaskCompletionState(filename, stage):\n",
    "    reference_time = 1548868837392\n",
    "    total_tasks = getTotalTasks(filename, stage)\n",
    "    tasks_completed = 0\n",
    "    stage_check = '\"Stage ID\":'+str(stage)\n",
    "    task_success_check = '{\"Reason\":\"Success\"}'\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "            if stage_check in line:\n",
    "                if '\"Event\":\"SparkListenerTaskEnd\"' and task_success_check in line:\n",
    "                    tasks_completed = tasks_completed + 1\n",
    "    if tasks_completed == total_tasks:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print (getTaskCompletionState(\"./sparkFiles/spark-events/app-20190221155750-0001\", 0))\n",
    "# app-20190225134146-0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.983333333333333\n"
     ]
    }
   ],
   "source": [
    "file = \"./sparkLogsData/app-20190130101035-0000\"\n",
    "def getStageDuration(filename, stage):\n",
    "    stage_duration = 0\n",
    "    stage_check = '\"Stage ID\":' + str(stage) + ','\n",
    "    start_time = ''\n",
    "    finish_time = ''\n",
    "    with open(filename) as openLog:\n",
    "            for line in openLog:\n",
    "                if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                    if stage_check in line:\n",
    "                        start_time = line.split('\"Submission Time\":')[1]\n",
    "                        start_time = start_time.split(',')[0]\n",
    "                        finish_time = line.split('\"Completion Time\":')[1]\n",
    "                        finish_time = finish_time.split(',')[0]\n",
    "                        break\n",
    "    #print (start_time)\n",
    "    TimestampUtc = \"\\/Date(\" + start_time + \")\\/\"\n",
    "    TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    \n",
    "    date_s = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "    #print (date_s)\n",
    "    \n",
    "    TimestampUtc = \"\\/Date(\" + finish_time + \")\\/\"\n",
    "    TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    date_f = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "    #print (date_f)\n",
    "\n",
    "    duration = date_f - date_s\n",
    "    duration = str(duration)\n",
    "    \n",
    "    duration = duration.split(':')\n",
    "    \n",
    "    duration_in_secs = (60*60*int(duration[0])) + (60*int(duration[1])) + int(duration[2])\n",
    "    \n",
    "    duration_in_mins = duration_in_secs/60\n",
    "    \n",
    "    return duration_in_mins\n",
    "\n",
    "print(getStageDuration(file, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Times are in Minutes\n",
      "\n",
      "Overall Stage Times\n",
      "[9.983333333333333, 0.016666666666666666]\n",
      "\n",
      "Mean Task Times Per Stage\n",
      "[5.213066666666666, 0.006633333333333334]\n",
      "Median Task Times Per Stage\n",
      "[5.804150000000001, 0.0067]\n",
      "\n",
      "Mean Scheduler Delay Per Stage\n",
      "[0.0, 0.0]\n",
      "Median Scheduler Delay Per Stage\n",
      "[0, 0]\n",
      "\n",
      "Mean Task Deserialization Dealy Per Stage\n",
      "[0.08004740576666668, 0.0038125453166666665]\n",
      "Median Task Deserailization Delay Per Stage\n",
      "[0.014256727583333333, 0.0006037435833333334]\n",
      "\n",
      "Mean Shuffle Read Time Per Stage\n",
      "[0.0, 1.6666666666666667e-05]\n",
      "Median Shuffle Read Time Per Stage\n",
      "[0.0, 0.0]\n",
      "\n",
      "Mean Shuffle Write Time Per Stage\n",
      "[0.00039824688333333334, 0.0]\n",
      "Median Shuffle Write Time Per Stage\n",
      "[0.0004622724416666667, 0.0]\n",
      "\n",
      "Mean GC Time Per Stage\n",
      "[1.6203, 0.0]\n",
      "Median GC Time Per Stage\n",
      "[1.968625, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#calculate all mean and median delays and task times\n",
    "\n",
    "#all times are in minutes\n",
    "\n",
    "filename = \"./sparkLogsData/app-20190130101035-0000\"\n",
    "\n",
    "stages = getStages(filename)\n",
    "meanTaskTimePerStage = []\n",
    "medianTaskTimePerStage = []\n",
    "\n",
    "meanSchedulerDelayPerStage = []\n",
    "meanTaskDeserializationTimePerStage = []\n",
    "meanShuffleReadTimePerStage = []\n",
    "meanShuffleWriteTimePerStage = []\n",
    "meanGCTimePerStage = []\n",
    "\n",
    "medianSchedulerDelayPerStage = []\n",
    "medianTaskDeserializationTimePerStage = []\n",
    "medianShuffleReadTimePerStage = []\n",
    "medianShuffleWriteTimePerStage = []\n",
    "medianGCTimePerStage = []\n",
    "\n",
    "stageDurations = []\n",
    "\n",
    "for stage in range(stages):\n",
    "    stageTime = getStageDuration(filename, stage)\n",
    "    stageDurations.append(stageTime)\n",
    "    \n",
    "    meanTaskTime = getMeanTaskTime(filename,stage)\n",
    "    meanTaskDeserializationTime =  getMeanTaskDeserializationTime(filename, stage)\n",
    "    meanShuffleReadTime = getMeanShuffleReadTime(filename, stage) \n",
    "    meanShuffleWriteTime = getMeanShuffleWriteTime(filename, stage)\n",
    "    meanGCTime = getMeanGCTime(filename, stage)\n",
    "    meanSchedulerDelay = getMeanSchedulerDelay(filename, stage)\n",
    "    \n",
    "    medianTaskTime =  getMedianTaskTime(filename, stage)\n",
    "    medianTaskDeserializationTime = getMedianTaskDeserializationTime(filename, stage)\n",
    "    medianShuffleReadTime = getMedianShuffleReadTime(filename, stage)\n",
    "    medianShuffleWriteTime = getMedianShuffleWriteTime(filename, stage)\n",
    "    medianGCTime = getMedianGCTime(filename, stage)\n",
    "    medianSchedulerDelay = getMedianSchedulerDelay(filename, stage)\n",
    "    \n",
    "    meanTaskTimePerStage.append(meanTaskTime)\n",
    "    medianTaskTimePerStage.append(medianTaskTime)\n",
    "    \n",
    "    meanSchedulerDelayPerStage.append(meanSchedulerDelay)\n",
    "    meanTaskDeserializationTimePerStage.append(meanTaskDeserializationTime)\n",
    "    meanShuffleReadTimePerStage.append(meanShuffleReadTime)\n",
    "    meanShuffleWriteTimePerStage.append(meanShuffleWriteTime)\n",
    "    meanGCTimePerStage.append(meanGCTime)\n",
    "\n",
    "    medianSchedulerDelayPerStage.append(medianSchedulerDelay)\n",
    "    medianTaskDeserializationTimePerStage.append(medianTaskDeserializationTime)\n",
    "    medianShuffleReadTimePerStage.append(medianShuffleReadTime)\n",
    "    medianShuffleWriteTimePerStage.append(medianShuffleWriteTime)\n",
    "    medianGCTimePerStage.append(medianGCTime)\n",
    "\n",
    "print(\"All Times are in Minutes\\n\")\n",
    "print(\"Overall Stage Times\")\n",
    "print(stageDurations)\n",
    "\n",
    "print(\"\\nMean Task Times Per Stage\")\n",
    "print(meanTaskTimePerStage)\n",
    "print(\"Median Task Times Per Stage\")\n",
    "print(medianTaskTimePerStage)\n",
    "\n",
    "print(\"\\nMean Scheduler Delay Per Stage\")\n",
    "print(meanSchedulerDelayPerStage)\n",
    "print(\"Median Scheduler Delay Per Stage\")\n",
    "print(medianSchedulerDelayPerStage)\n",
    "\n",
    "print(\"\\nMean Task Deserialization Dealy Per Stage\")\n",
    "print(meanTaskDeserializationTimePerStage)\n",
    "print(\"Median Task Deserailization Delay Per Stage\")\n",
    "print(medianTaskDeserializationTimePerStage)\n",
    "\n",
    "print(\"\\nMean Shuffle Read Time Per Stage\")\n",
    "print(meanShuffleReadTimePerStage)\n",
    "print(\"Median Shuffle Read Time Per Stage\")\n",
    "print(medianShuffleReadTimePerStage)\n",
    "\n",
    "\n",
    "print(\"\\nMean Shuffle Write Time Per Stage\")\n",
    "print(meanShuffleWriteTimePerStage)\n",
    "print(\"Median Shuffle Write Time Per Stage\")\n",
    "print(medianShuffleWriteTimePerStage)\n",
    "\n",
    "\n",
    "print(\"\\nMean GC Time Per Stage\")\n",
    "print(meanGCTimePerStage)\n",
    "print(\"Median GC Time Per Stage\")\n",
    "print(medianGCTimePerStage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

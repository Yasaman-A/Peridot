{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/user/bin/env python\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "import xlwt\n",
    "import datetime\n",
    "import numpy\n",
    "\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAll functions below to extract task metrics  (getExecutorRunTime, getExecutorCPURunTime, getExecutorDeserializeCPUTime,\\ngetExecutorDeserializeTime, getShuffleWriteTime) output results in seconds for a particular task.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "All functions below to extract task metrics  (getExecutorRunTime, getExecutorCPURunTime, getExecutorDeserializeCPUTime,\n",
    "getExecutorDeserializeTime, getShuffleWriteTime) output results in seconds for a particular task.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"./sparkFiles/spark-events/app-20200214152759-0009\"\n",
    "def getStages(filename):\n",
    "    stage_count = 0\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "            if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                if '\"Stage ID\":' in line:\n",
    "                    #print(line)\n",
    "                    stage_count = stage_count+1\n",
    "    \n",
    "    #print(stage_count)\n",
    "\n",
    "    return stage_count\n",
    "\n",
    "getStages(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def getTasks(filename, stage):\n",
    "    total = 0\n",
    "    stage_check = '\"Stage ID\":'+str(stage) + ','\n",
    "#     task_success_check = '{\"Reason\":\"Success\"}'\n",
    "    with open(filename) as openLog:\n",
    "        for line in openLog:\n",
    "                if '\"Event\":\"SparkListenerStageSubmitted\"' and stage_check in line:\n",
    "                        if '\"Number of Tasks\":' in line:\n",
    "                            partB = line.split('\"Number of Tasks\":')[1]\n",
    "                            partB = partB.split(\",\")\n",
    "                            tasks = partB[0] \n",
    "                            total = int(tasks)\n",
    "\n",
    "        return total\n",
    "print(getTasks(file,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6263\n"
     ]
    }
   ],
   "source": [
    "def getTaskDuration(filename, stage, tid):\n",
    "\n",
    "    executorRunTime = getExecutorRunTime(filename, stage, tid)\n",
    "    \n",
    "    task_duration = executorRunTime\n",
    "    task_duration = round(task_duration, 4)\n",
    "    \n",
    "    return task_duration\n",
    "\n",
    "print(getTaskDuration(file, 1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.966666666666667\n"
     ]
    }
   ],
   "source": [
    "#to calculate total time taken by a stage\n",
    "file = \"./sparkFiles/spark-events/app-20200214152759-0009\"\n",
    "def getStageDuration(filename, stage):\n",
    "    stage_duration = 0\n",
    "    stage_check = '\"Stage ID\":' + str(stage) + ','\n",
    "    start_time = ''\n",
    "    finish_time = ''\n",
    "    with open(filename) as openLog:\n",
    "            for line in openLog:\n",
    "                if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                    if stage_check in line:\n",
    "                        start_time = line.split('\"Submission Time\":')[1]\n",
    "                        start_time = start_time.split(',')[0]\n",
    "                        finish_time = line.split('\"Completion Time\":')[1]\n",
    "                        finish_time = finish_time.split(',')[0]\n",
    "                        break\n",
    "\n",
    "    TimestampUtc = \"\\/Date(\" + start_time + \")\\/\"\n",
    "    TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    date_s = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "#     print (date_s)\n",
    "    \n",
    "    TimestampUtc = \"\\/Date(\" + finish_time + \")\\/\"\n",
    "    TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "\n",
    "    date_f = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "#     print (date_f)\n",
    "\n",
    "    duration = date_f - date_s\n",
    "    duration = str(duration)\n",
    "    \n",
    "    duration = duration.split(':')\n",
    "    \n",
    "    duration_in_secs = (60*60*int(duration[0])) + (60*int(duration[1])) + int(duration[2])\n",
    "    \n",
    "    duration_in_mins = duration_in_secs/60\n",
    "    \n",
    "    return duration_in_mins\n",
    "\n",
    "print(getStageDuration(file, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 3, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51], [{2, 3}, {8, 7}, {10, 11}, {12, 13}, {16, 15}, {17, 18}, {20, 21}, {24, 22, 23}, {25, 26}, {27, 28}, {32, 33}, {35, 36}, {37, 38}, {40, 41}, {43, 44}, {45, 46}, {48, 47}, {50, 51}])\n"
     ]
    }
   ],
   "source": [
    "#get parallel stages from an application\n",
    "file = \"./sparkFiles/spark-events/app-20190507123104-0000\"\n",
    "\n",
    "def getParallelStages(filename):\n",
    "    stage_duration = 0\n",
    "    start_time = ''\n",
    "    finish_time = ''\n",
    "    stage_id = ''\n",
    "    stages = {}\n",
    "    parallel_stages = {}\n",
    "    parallel_stages_filetered = []\n",
    "    pstages_final =[]\n",
    "    \n",
    "    with open(filename) as openLog:\n",
    "            for line in openLog:\n",
    "                if '\"Event\":\"SparkListenerStageCompleted\"' in line:\n",
    "                        stage_times = []\n",
    "                        start_time = line.split('\"Submission Time\":')[1]\n",
    "                        start_time = start_time.split(',')[0]\n",
    "                        \n",
    "                        TimestampUtc = \"\\/Date(\" + start_time + \")\\/\"\n",
    "                        TimestampUtc = re.split('\\(|\\)', TimestampUtc)[1][:10]\n",
    "                        date_s = datetime.datetime.fromtimestamp(int(TimestampUtc))\n",
    "                        date_s = str(date_s)\n",
    "                        \n",
    "                        stage_id = line.split('\"Stage ID\":')[1]\n",
    "                        stage_id = stage_id.split(',')[0]\n",
    "                        stages[stage_id] = date_s\n",
    "                 \n",
    "    \n",
    "    \n",
    "    for stage,time in stages.items():\n",
    "        parallel_stages.setdefault(time, set()).add(int(stage))\n",
    "    \n",
    "#     print(parallel_stages)\n",
    "    \n",
    "    for key, values in parallel_stages.items():\n",
    "        parallel_stages_filtered = [values for key, values in parallel_stages.items() \n",
    "                              if len(values) > 1]\n",
    "        \n",
    "    for i in parallel_stages_filtered:\n",
    "        list_i = list(i)\n",
    "        pstages_final += list_i\n",
    "\n",
    "    pstages_final.sort()\n",
    "    return pstages_final, parallel_stages_filtered\n",
    "#     print(pstages_final)\n",
    "    \n",
    "\n",
    "print(getParallelStages(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of waves in a stage\n",
    "def getWaves(numOfTasks, cores):\n",
    "    waves = numOfTasks/cores\n",
    "    waves = math.ceil(waves)\n",
    "    \n",
    "    return waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract variable stages\n",
    "def getScalingStages(ref1_stagetimes, ref2_stagetimes, ref1_partitions, ref2_partitions, stages):\n",
    "    scalingstages = []\n",
    "    for i in range(stages):\n",
    "        if ref1_partitions[i] != ref2_partitions[i]:\n",
    "                    scalingstages.append(i)\n",
    "                \n",
    "    return scalingstages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.85\n"
     ]
    }
   ],
   "source": [
    "#to get overall application time\n",
    "def getApplicationTime(filename):\n",
    "    stages = getStages(filename)\n",
    "    total_application_time = 0\n",
    "    \n",
    "    for i in range(stages):\n",
    "        stageduration = getStageDuration(filename, i)\n",
    "        total_application_time = total_application_time + stageduration\n",
    "        \n",
    "    return total_application_time\n",
    "\n",
    "print(getApplicationTime(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage  0\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  15.266666666666667\n",
      "Average Wave Time:  1.1743589743589744\n",
      "\n",
      "Stage  1\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.0\n",
      "Average Wave Time:  0.0\n",
      "\n",
      "Stage  2\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.016666666666666666\n",
      "Average Wave Time:  0.016666666666666666\n",
      "\n",
      "Stage  3\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  10.183333333333334\n",
      "Average Wave Time:  0.7833333333333333\n",
      "\n",
      "Stage  4\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  0.016666666666666666\n",
      "Average Wave Time:  0.001282051282051282\n",
      "\n",
      "Stage  5\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  9.333333333333334\n",
      "Average Wave Time:  0.717948717948718\n",
      "\n",
      "Stage  6\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  6.316666666666666\n",
      "Average Wave Time:  0.4858974358974359\n",
      "\n",
      "Stage  7\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.016666666666666666\n",
      "Average Wave Time:  0.016666666666666666\n",
      "\n",
      "Stage  8\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.0\n",
      "Average Wave Time:  0.0\n",
      "\n",
      "Stage  9\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.016666666666666666\n",
      "Average Wave Time:  0.016666666666666666\n",
      "\n",
      "Stage  10\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.0\n",
      "Average Wave Time:  0.0\n",
      "\n",
      "Stage  11\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.0\n",
      "Average Wave Time:  0.0\n",
      "\n",
      "Stage  12\n",
      "Number of Tasks:  1\n",
      "Number of Waves:  1\n",
      "Stage Duration:  0.0\n",
      "Average Wave Time:  0.0\n",
      "\n",
      "Stage  13\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  9.816666666666666\n",
      "Average Wave Time:  0.7551282051282051\n",
      "\n",
      "Stage  14\n",
      "Number of Tasks:  64\n",
      "Number of Waves:  13\n",
      "Stage Duration:  6.333333333333333\n",
      "Average Wave Time:  0.48717948717948717\n",
      "\n",
      "Average Wave Times Per Stage\n",
      "[1.1743589743589744, 0.0, 0.016666666666666666, 0.7833333333333333, 0.001282051282051282, 0.717948717948718, 0.4858974358974359, 0.016666666666666666, 0.0, 0.016666666666666666, 0.0, 0.0, 0.0, 0.7551282051282051, 0.48717948717948717]\n",
      "\n",
      "Stage Times\n",
      "[15.266666666666667, 0.0, 0.016666666666666666, 10.183333333333334, 0.016666666666666666, 9.333333333333334, 6.316666666666666, 0.016666666666666666, 0.0, 0.016666666666666666, 0.0, 0.0, 0.0, 9.816666666666666, 6.333333333333333]\n"
     ]
    }
   ],
   "source": [
    "#get average times for each stage\n",
    "def getAvgWaveTimes(file, cores):\n",
    "    stages = getStages(file)\n",
    "    avgwavetimes = []\n",
    "    stagedurations = []\n",
    "    wavesperstage = []\n",
    "\n",
    "    for stage in range(stages):\n",
    "\n",
    "        tasks = getTasks(file, stage)\n",
    "\n",
    "        print(\"\\nStage \", stage)\n",
    "        waves = getWaves(tasks, cores)\n",
    "        wavesperstage.append(waves)\n",
    "        print(\"Number of Tasks: \", tasks)\n",
    "        print(\"Number of Waves: \", waves)\n",
    "\n",
    "        stagetime = getStageDuration(file, stage)\n",
    "\n",
    "        avg_task_time = stagetime/waves\n",
    "\n",
    "        avgwavetimes.append(avg_task_time)\n",
    "        print(\"Stage Duration: \", stagetime)\n",
    "        print(\"Average Wave Time: \", avg_task_time)\n",
    "\n",
    "        stagedurations.append(stagetime)\n",
    "\n",
    "    print(\"\\nAverage Wave Times Per Stage\")\n",
    "    print(avgwavetimes)\n",
    "\n",
    "    print(\"\\nStage Times\")\n",
    "    print(stagedurations)\n",
    "    \n",
    "file = \"./sparkFiles/spark-events/app-20190703111240-0003\"\n",
    "getAvgWaveTimes(file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Stage Group in Ref 1: [2, 12, 2]\n",
      "Average Task Time for Ref 1: 0.07083333333333333\n",
      "Maximum parallel Stage Time for Ref 1: 0.2833333333333333\n",
      "Waves for Stage 1: 4\n",
      "Parallel Stage Group in Ref 2: [2, 24, 2]\n",
      "Average Task Time for Ref 2: 0.09166666666666667\n",
      "Maximum parallel Stage Time for Ref 2: 0.55\n",
      "Waves for Stage 2: 6\n",
      "[0.03333333333333333, 0.2833333333333333, 0.016666666666666666]\n",
      "0.3333333333333333\n",
      "Constant Time 1: 0.06666666666666665\n",
      "Constant Time 2: 0.08333333333333326\n",
      "Average Partition Count: 15\n",
      "Average Wave Times: [0.08125]\n",
      "Constant Time: 0.07499999999999996\n"
     ]
    }
   ],
   "source": [
    "# gather reference data\n",
    "ref1 = \"./sparkFiles/spark-events/app-20190913185420-0030\"\n",
    "ref2 = \"./sparkFiles/spark-events/app-20190913203944-0054\"\n",
    "\n",
    "ref_cores = 5\n",
    "\n",
    "ref1_stagedurations = [] \n",
    "ref2_stagedurations = []\n",
    "\n",
    "ref1_tasks = []\n",
    "ref2_tasks= []\n",
    "\n",
    "ref1_stages = getStages(ref1)\n",
    "ref2_stages = getStages(ref2)\n",
    "\n",
    "totalScalingTime1 = 0\n",
    "totalScalingTime2 = 0\n",
    "\n",
    "avgWaveTimes = []\n",
    "\n",
    "ref1_parallelstages, ref1_parallelstagesets = getParallelStages(ref1)\n",
    "ref2_parallelstages, ref2_parallelstagesets = getParallelStages(ref2)\n",
    "\n",
    "const_parallelstagepartitions = []\n",
    "parallel_stage_set = []\n",
    "\n",
    "for i in range(ref1_stages):\n",
    "    ref1_stagedurations.append(getStageDuration(ref1, i))\n",
    "    ref1_tasks.append(getTasks(ref1, i))\n",
    "    \n",
    "for i in range(ref2_stages):\n",
    "    ref2_stagedurations.append(getStageDuration(ref2, i))\n",
    "    ref2_tasks.append(getTasks(ref2, i))\n",
    "\n",
    "if not all(ref1_parallelstages):\n",
    "    ParallelStages = False\n",
    "else:\n",
    "    ParallelStages = True\n",
    "\n",
    "scalingStages = getScalingStages(ref1_stagedurations, ref2_stagedurations, ref1_tasks, ref2_tasks, ref1_stages)    \n",
    "\n",
    "ParallelStages = True\n",
    "\n",
    "if ParallelStages == False:\n",
    "    print(\"Scaling Stages: \", scalingStages)\n",
    "    partitionCounts = []\n",
    "    for i in range(len(scalingStages)):\n",
    "        stagetime1 = getStageDuration(ref1, scalingStages[i])\n",
    "        partitions1 = getTasks(ref1, scalingStages[i])\n",
    "        waves1 = getWaves(partitions1, ref_cores)\n",
    "        avgTaskTime1 = stagetime1/waves1\n",
    "\n",
    "        stagetime2 = getStageDuration(ref2, scalingStages[i])\n",
    "        partitions2 = getTasks(ref2, scalingStages[i])\n",
    "        waves2 = getWaves(partitions2, ref_cores)\n",
    "        avgTaskTime2 = stagetime2/waves2\n",
    "        average_partition_count = (partitions1 + (partitions2/2))/2\n",
    "        partitionCounts.append(average_partition_count)\n",
    "\n",
    "        avgTaskTime = (avgTaskTime1 + avgTaskTime2)/2\n",
    "        avgWaveTimes.append(avgTaskTime)\n",
    "\n",
    "        totalScalingTime1 = totalScalingTime1 + stagetime1\n",
    "        totalScalingTime2 = totalScalingTime2 + stagetime2\n",
    "\n",
    "\n",
    "    constTime1 = getApplicationTime(ref1) - totalScalingTime1\n",
    "    constTime2 = getApplicationTime(ref2) - totalScalingTime2\n",
    "    constantTime = (constTime1 + constTime2)/2\n",
    "    print(\"Average Partition Count:\", partitionCounts)\n",
    "    print(\"Average Wave Times:\", avgWaveTimes)\n",
    "    print(\"Constant Time:\", constantTime)\n",
    "    print(\"Parallel Stage Set:\", parallel_stage_set)\n",
    "\n",
    "else:\n",
    "    pstage_durations1 = []\n",
    "    pstage_partitions1 = []\n",
    "    pstage_durations2 = []\n",
    "    pstage_partitions2 = []\n",
    "    partitionCounts = []\n",
    "    scaling_parallelstages1 = list(set(scalingStages).intersection(ref1_parallelstages))\n",
    "    scaling_parallelstages2 = list(set(scalingStages).intersection(ref2_parallelstages))\n",
    "\n",
    "    \n",
    "    for j in range(len(scaling_parallelstages1)):\n",
    "        for k in ref1_parallelstagesets:\n",
    "            if scaling_parallelstages1[j] in k:\n",
    "                for x in k:\n",
    "                    pstage_durations1.append(getStageDuration(ref1, x))\n",
    "                    pstage_partitions1.append(getTasks(ref1, x))\n",
    "                break\n",
    "        break\n",
    "    print(\"Parallel Stage Group in Ref 1:\", pstage_partitions1)\n",
    "        \n",
    "    max_pstage_duration1 = max(pstage_durations1)\n",
    "    tot_pstage_partitions1 = sum(pstage_partitions1)\n",
    "    waves1 = getWaves(tot_pstage_partitions1, ref_cores)\n",
    "    avgTaskTime1 = max_pstage_duration1/waves1\n",
    "    print(\"Average Task Time for Ref 1:\", avgTaskTime1)\n",
    "    print(\"Maximum parallel Stage Time for Ref 1:\", max_pstage_duration1)\n",
    "    print(\"Waves for Stage 1:\", waves1)\n",
    "    \n",
    "    for j in range(len(scaling_parallelstages2)):\n",
    "        for k in ref2_parallelstagesets:\n",
    "            if scaling_parallelstages2[j] in k:\n",
    "                for x in k:\n",
    "                    pstage_durations2.append(getStageDuration(ref2, x))\n",
    "                    pstage_partitions2.append(getTasks(ref2, x))\n",
    "                break\n",
    "        break\n",
    "                \n",
    "    print(\"Parallel Stage Group in Ref 2:\", pstage_partitions2)\n",
    "    max_pstage_duration2 = max(pstage_durations2)\n",
    "    tot_pstage_partitions2 = sum(pstage_partitions2)\n",
    "    \n",
    "    waves2 = getWaves(tot_pstage_partitions2, ref_cores)\n",
    "    avgTaskTime2 = max_pstage_duration2/waves2\n",
    "    print(\"Average Task Time for Ref 2:\", avgTaskTime2)\n",
    "    print(\"Maximum parallel Stage Time for Ref 2:\", max_pstage_duration2)\n",
    "    print(\"Waves for Stage 2:\", waves2)\n",
    "    avgTaskTime = (avgTaskTime1 + avgTaskTime2)/2\n",
    "    avgWaveTimes.append(avgTaskTime)\n",
    "    print(pstage_durations1)\n",
    "    print(sum(pstage_durations1))\n",
    "    constTime1 = getApplicationTime(ref1) - sum(pstage_durations1)\n",
    "    constTime2 = getApplicationTime(ref2) - sum(pstage_durations2)\n",
    "    print(\"Constant Time 1:\", constTime1)\n",
    "    print(\"Constant Time 2:\", constTime2)\n",
    "    constantTime = (constTime1 + constTime2)/2\n",
    "    \n",
    "    avg_partition_count = math.ceil((tot_pstage_partitions1 + tot_pstage_partitions2/2)/2)\n",
    "    partitionCounts.append(avg_partition_count)\n",
    "\n",
    "    print(\"Average Partition Count:\", avg_partition_count)\n",
    "    print(\"Average Wave Times:\", avgWaveTimes)\n",
    "    print(\"Constant Time:\", constantTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Application Duration: 1.61875\n"
     ]
    }
   ],
   "source": [
    "#get predictions\n",
    "def predictApplicationTime(_cores, _data):\n",
    "    cores = _cores\n",
    "\n",
    "    new_stage_times = []\n",
    "\n",
    "    input_size = _data\n",
    "\n",
    "    for s in range(len(partitionCounts)):\n",
    "        newWaveNumber = getWaves(partitionCounts[s]*input_size, cores)\n",
    "\n",
    "        new_stage_times.append(newWaveNumber*avgWaveTimes[s])\n",
    "\n",
    "    scaledTime = sum(new_stage_times)\n",
    "    predictedTime = scaledTime + constantTime\n",
    "\n",
    "    print(\"Estimated Application Duration:\", predictedTime)\n",
    "    \n",
    "predictApplicationTime(40,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
